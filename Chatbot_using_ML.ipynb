{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudhanshu-2004/chatbot-using-ML/blob/main/Chatbot_using_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ivE417SCec2J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Embedding,GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-cGyNaUlh1r"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3F9ydpdg1dZ"
      },
      "source": [
        "# **import dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GQtraxHRg0Lk"
      },
      "outputs": [],
      "source": [
        "with open('/content/intents.json')as file:\n",
        "  data=json.load(file)\n",
        "\n",
        "\n",
        "training_sentences=[]\n",
        "training_labels=[]\n",
        "labels=[]\n",
        "responses=[]\n",
        "\n",
        "\n",
        "\n",
        "for intent in data['intents']:\n",
        "  for pattern in intent['patterns']:\n",
        "    training_sentences.append(pattern)\n",
        "    training_labels.append(intent['tag'])\n",
        "\n",
        "  responses.append(intent['responses'])\n",
        "\n",
        "\n",
        "  if intent['tag'] not in labels:\n",
        "    labels.append(intent['tag'])\n",
        "\n",
        "\n",
        "num_classes=len(labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swGtmZ-LlMSD"
      },
      "source": [
        "# **ENCODE LABELS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4yBDp0L2laHn"
      },
      "outputs": [],
      "source": [
        "lbl_encoder = LabelEncoder()\n",
        "lbl_encoder.fit(training_labels)\n",
        "training_labels = lbl_encoder.transform(training_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbDirXOxnQBa"
      },
      "source": [
        "# **TOKENIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CcUZ5puqnYd4"
      },
      "outputs": [],
      "source": [
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_len = 20\n",
        "oov_token = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QKVYlN2nwid"
      },
      "source": [
        "# **TRAINING NEURAL NETWORKS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phy4r8mXn9pS",
        "outputId": "dbe66cd8-d8f7-46d4-ed74-3f6962783e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 20, 16)            16000     \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 16)                0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                272       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16408 (64.09 KB)\n",
            "Trainable params: 16408 (64.09 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 3s 216ms/step - loss: 2.0787 - accuracy: 0.1515\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 2.0768 - accuracy: 0.1515\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 158ms/step - loss: 2.0755 - accuracy: 0.1515\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 162ms/step - loss: 2.0746 - accuracy: 0.1818\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0737 - accuracy: 0.3333\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0728 - accuracy: 0.2121\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0719 - accuracy: 0.2121\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 2.0712 - accuracy: 0.2121\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0706 - accuracy: 0.2121\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0699 - accuracy: 0.2121\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 155ms/step - loss: 2.0691 - accuracy: 0.2121\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.0682 - accuracy: 0.2121\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0673 - accuracy: 0.2121\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0665 - accuracy: 0.2121\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.0656 - accuracy: 0.2121\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.0650 - accuracy: 0.2121\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0644 - accuracy: 0.2121\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0637 - accuracy: 0.2121\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 2.0629 - accuracy: 0.2121\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.0620 - accuracy: 0.2121\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import GlobalAveragePooling1D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "\n",
        "# Now you can use GlobalAveragePooling1D\n",
        "model.add(GlobalAveragePooling1D())\n",
        "\n",
        "\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "epochs = 20\n",
        "history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVMqlsoBqJAA"
      },
      "source": [
        "# **SAVE TRAINED MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N1duqvdLqP9h"
      },
      "outputs": [],
      "source": [
        "model.save(\"chat_model\")\n",
        "\n",
        "import pickle\n",
        "\n",
        "# to save the fitted tokenizer\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# to save the fitted label encoder\n",
        "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
        "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxFp1QeerAWr"
      },
      "source": [
        "# **CHATBOT CONVERSATION**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXSJIfTMrN6H",
        "outputId": "ec673fe2-0b74-4580-9416-d0e3ac395171"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n",
            "Start messaging with the bot (type quit to stop)!\n",
            "User: sudhanshui\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "ChatBot: Tell me how can assist you\n",
            "User: help\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "ChatBot: Yes Sure, How can I support you\n",
            "User: complaint\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "ChatBot: Tell me how can assist you\n",
            "User: create account\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "ChatBot: Tell me your problem to assist you\n",
            "User: quit\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "!pip install colorama\n",
        "import colorama\n",
        "colorama.init()\n",
        "from colorama import Fore, Style, Back\n",
        "\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "with open(\"intents.json\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "\n",
        "def chat():\n",
        "    # load trained model\n",
        "    model = keras.models.load_model('chat_model')\n",
        "\n",
        "    # load tokenizer object\n",
        "    with open('tokenizer.pickle', 'rb') as handle:\n",
        "        tokenizer = pickle.load(handle)\n",
        "\n",
        "    # load label encoder object\n",
        "    with open('label_encoder.pickle', 'rb') as enc:\n",
        "        lbl_encoder = pickle.load(enc)\n",
        "\n",
        "    # parameters\n",
        "    max_len = 20\n",
        "\n",
        "    while True:\n",
        "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
        "        inp = input()\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
        "                                             truncating='post', maxlen=max_len))\n",
        "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
        "\n",
        "        for i in data['intents']:\n",
        "            if i['tag'] == tag:\n",
        "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n",
        "\n",
        "        # print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\n",
        "\n",
        "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
        "chat()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1fuKL7edOWL8lAvCSc2kD2wIlNoxS98pf",
      "authorship_tag": "ABX9TyN/jMyYQt2uPkElh9KyrAPv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}